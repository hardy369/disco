import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from typing import Tuple, List, Optional
import warnings
warnings.filterwarnings('ignore')

class QuantumReservoirComputing:
    """
    Quantum Reservoir Computing with configurable noise injection
    """
    
    def __init__(self, 
                 n_qubits: int = 8,
                 reservoir_size: int = 100,
                 spectral_radius: float = 0.9,
                 input_scaling: float = 0.3,
                 noise_factors: dict = None,
                 dt: float = 0.1):
        """
        Initialize Quantum Reservoir Computing system
        
        Args:
            n_qubits: Number of qubits in quantum system
            reservoir_size: Size of classical reservoir
            spectral_radius: Spectral radius for reservoir stability
            input_scaling: Input scaling factor
            noise_factors: Dictionary of noise parameters
            dt: Time step for evolution
        """
        self.n_qubits = n_qubits
        self.reservoir_size = reservoir_size
        self.spectral_radius = spectral_radius
        self.input_scaling = input_scaling
        self.dt = dt
        
        # Default noise factors if not provided
        if noise_factors is None:
            self.noise_factors = {
                'amplitude_damping': 0.01,      # T1 relaxation
                'phase_damping': 0.02,          # T2 dephasing
                'depolarizing': 0.005,          # General decoherence
                'thermal': 0.001,               # Thermal noise
                'shot_noise': 0.1,              # Measurement noise
                'control_noise': 0.02           # Control field fluctuations
            }
        else:
            self.noise_factors = noise_factors
            
        self._initialize_reservoir()
        self._initialize_quantum_system()
    
    def _initialize_reservoir(self):
        """Initialize classical reservoir connections"""
        # Create random reservoir matrix
        W = np.random.randn(self.reservoir_size, self.reservoir_size)
        
        # Scale to desired spectral radius
        eigenvals = np.linalg.eigvals(W)
        W = W * (self.spectral_radius / np.max(np.abs(eigenvals)))
        
        self.W_reservoir = W
        
        # Input and output weights
        self.W_in = np.random.randn(self.reservoir_size, 1) * self.input_scaling
        self.W_out = None  # Will be trained
        
        # Quantum-classical coupling
        self.W_quantum = np.random.randn(self.reservoir_size, 2**self.n_qubits) * 0.1
    
    def _initialize_quantum_system(self):
        """Initialize quantum system parameters"""
        self.dim = 2**self.n_qubits
        
        # Random quantum Hamiltonian (Ising-like model)
        self.H = self._create_quantum_hamiltonian()
        
        # Initial quantum state (ground state + small perturbation)
        self.quantum_state = np.zeros(self.dim, dtype=complex)
        self.quantum_state[0] = 1.0  # Ground state
        
        # Add small random perturbation
        perturbation = np.random.randn(self.dim) + 1j * np.random.randn(self.dim)
        perturbation *= 0.01
        self.quantum_state += perturbation
        self.quantum_state /= np.linalg.norm(self.quantum_state)
    
    def _create_quantum_hamiltonian(self):
        """Create quantum Hamiltonian with tunable parameters"""
        H = np.zeros((self.dim, self.dim), dtype=complex)
        
        # Single qubit terms (Pauli-Z)
        for i in range(self.n_qubits):
            pauli_z = self._pauli_z_on_qubit(i)
            H += np.random.uniform(0.5, 1.5) * pauli_z
        
        # Two-qubit interactions (Pauli-X âŠ— Pauli-X)
        for i in range(self.n_qubits - 1):
            xx_interaction = self._xx_interaction(i, i+1)
            H += np.random.uniform(0.1, 0.5) * xx_interaction
        
        return H
    
    def _pauli_z_on_qubit(self, qubit_idx: int):
        """Create Pauli-Z operator on specific qubit"""
        pauliz = np.array([[1, 0], [0, -1]], dtype=complex)
        identity = np.eye(2, dtype=complex)
        
        operators = []
        for i in range(self.n_qubits):
            if i == qubit_idx:
                operators.append(pauliz)
            else:
                operators.append(identity)
        
        result = operators[0]
        for op in operators[1:]:
            result = np.kron(result, op)
        
        return result
    
    def _xx_interaction(self, qubit1: int, qubit2: int):
        """Create XX interaction between two qubits"""
        paulix = np.array([[0, 1], [1, 0]], dtype=complex)
        identity = np.eye(2, dtype=complex)
        
        operators = []
        for i in range(self.n_qubits):
            if i == qubit1 or i == qubit2:
                operators.append(paulix)
            else:
                operators.append(identity)
        
        result = operators[0]
        for op in operators[1:]:
            result = np.kron(result, op)
        
        return result
    
    def _apply_quantum_noise(self, state: np.ndarray) -> np.ndarray:
        """Apply various quantum noise models"""
        noisy_state = state.copy()
        
        # Amplitude damping (T1 relaxation)
        if self.noise_factors['amplitude_damping'] > 0:
            gamma = self.noise_factors['amplitude_damping']
            # Simplified amplitude damping
            decay = np.exp(-gamma * self.dt)
            noisy_state *= decay
            
            # Add ground state population
            ground_contribution = np.sqrt(1 - decay**2) * np.random.exponential(0.1)
            if len(noisy_state) > 0:
                noisy_state[0] += ground_contribution
        
        # Phase damping (T2 dephasing)
        if self.noise_factors['phase_damping'] > 0:
            gamma_phi = self.noise_factors['phase_damping']
            random_phases = np.random.normal(0, np.sqrt(gamma_phi * self.dt), len(noisy_state))
            phase_factors = np.exp(1j * random_phases)
            noisy_state *= phase_factors
        
        # Depolarizing noise
        if self.noise_factors['depolarizing'] > 0:
            p = self.noise_factors['depolarizing']
            if np.random.random() < p:
                # Mix with maximally mixed state
                mixed_state = np.ones(len(noisy_state), dtype=complex) / np.sqrt(len(noisy_state))
                noisy_state = np.sqrt(1-p) * noisy_state + np.sqrt(p) * mixed_state
        
        # Thermal noise
        if self.noise_factors['thermal'] > 0:
            thermal_noise = np.random.normal(0, self.noise_factors['thermal'], len(noisy_state))
            thermal_noise += 1j * np.random.normal(0, self.noise_factors['thermal'], len(noisy_state))
            noisy_state += thermal_noise
        
        # Control noise (Hamiltonian fluctuations)
        if self.noise_factors['control_noise'] > 0:
            control_fluctuation = np.random.normal(0, self.noise_factors['control_noise'])
            H_noisy = self.H * (1 + control_fluctuation)
            
            # Apply noisy evolution
            U_noisy = np.linalg.matrix_power(
                np.eye(self.dim) - 1j * H_noisy * self.dt, 1
            )
            noisy_state = U_noisy @ noisy_state
        
        # Renormalize
        norm = np.linalg.norm(noisy_state)
        if norm > 1e-10:
            noisy_state /= norm
        
        return noisy_state
    
    def _evolve_quantum_state(self, input_signal: float):
        """Evolve quantum state with input and noise"""
        # Add input-dependent term to Hamiltonian
        H_driven = self.H + input_signal * self._pauli_z_on_qubit(0)
        
        # Quantum evolution (simplified Trotter step)
        U = np.eye(self.dim) - 1j * H_driven * self.dt
        self.quantum_state = U @ self.quantum_state
        
        # Apply noise
        self.quantum_state = self._apply_quantum_noise(self.quantum_state)
        
        # Extract observables (probabilities)
        probabilities = np.abs(self.quantum_state)**2
        
        # Add shot noise to measurements
        if self.noise_factors['shot_noise'] > 0:
            shot_noise = np.random.normal(0, self.noise_factors['shot_noise'], len(probabilities))
            probabilities += shot_noise
            probabilities = np.clip(probabilities, 0, 1)
            probabilities /= np.sum(probabilities)  # Renormalize
        
        return probabilities
    
    def _update_reservoir(self, quantum_observables: np.ndarray, input_val: float):
        """Update classical reservoir state"""
        if not hasattr(self, 'reservoir_state'):
            self.reservoir_state = np.zeros(self.reservoir_size)
        
        # Reservoir dynamics with quantum coupling
        quantum_input = self.W_quantum @ quantum_observables
        
        self.reservoir_state = np.tanh(
            self.W_reservoir @ self.reservoir_state + 
            self.W_in.flatten() * input_val +
            quantum_input * 0.1  # Quantum influence scaling
        )
        
        return self.reservoir_state.copy()
    
    def train(self, X_train: np.ndarray, y_train: np.ndarray, reg_param: float = 1e-6):
        """Train the quantum reservoir system"""
        n_samples = len(X_train)
        states_history = []
        
        print("Training quantum reservoir...")
        
        # Reset quantum state
        self._initialize_quantum_system()
        
        # Collect reservoir states
        for i in range(n_samples):
            # Evolve quantum system
            quantum_obs = self._evolve_quantum_state(X_train[i])
            
            # Update reservoir
            reservoir_state = self._update_reservoir(quantum_obs, X_train[i])
            
            states_history.append(reservoir_state)
        
        # Train output weights using ridge regression
        X_states = np.array(states_history)
        self.W_out = np.linalg.solve(
            X_states.T @ X_states + reg_param * np.eye(self.reservoir_size),
            X_states.T @ y_train
        )
        
        print(f"Training completed. Output weights shape: {self.W_out.shape}")
    
    def predict(self, X_test: np.ndarray) -> np.ndarray:
        """Make predictions using trained quantum reservoir"""
        if self.W_out is None:
            raise ValueError("Model must be trained before prediction")
        
        n_samples = len(X_test)
        predictions = []
        
        # Reset quantum state for prediction
        self._initialize_quantum_system()
        
        for i in range(n_samples):
            # Evolve quantum system
            quantum_obs = self._evolve_quantum_state(X_test[i])
            
            # Update reservoir
            reservoir_state = self._update_reservoir(quantum_obs, X_test[i])
            
            # Make prediction
            pred = np.dot(reservoir_state, self.W_out)
            predictions.append(pred)
        
        return np.array(predictions)

def generate_narma2_dataset(n_samples: int = 2000, delay: int = 2) -> Tuple[np.ndarray, np.ndarray]:
    """
    Generate NARMA2 (Nonlinear Auto-Regressive Moving Average) benchmark dataset
    
    The NARMA2 task is defined as:
    y(n+1) = 0.4 * y(n) + 0.4 * y(n) * y(n-d) + 0.6 * u(n)^3 + 0.1
    
    where:
    - y(n) is the output at time n
    - u(n) is the input at time n (uniform random [0,0.5])
    - d is the delay parameter (default 2)
    
    Args:
        n_samples: Number of samples to generate
        delay: Delay parameter for the NARMA system
        
    Returns:
        Tuple of (inputs, targets)
    """
    print(f"Generating NARMA2 dataset with {n_samples} samples and delay={delay}")
    
    # Generate random input sequence u(n) ~ Uniform[0, 0.5]
    np.random.seed(42)  # For reproducibility
    u = np.random.uniform(0, 0.5, n_samples + delay + 1)
    
    # Initialize output sequence
    y = np.zeros(n_samples + delay + 1)
    
    # Initial conditions (small random values)
    y[:delay+1] = np.random.uniform(0, 0.1, delay+1)
    
    # Generate NARMA2 time series
    for n in range(delay, n_samples + delay):
        y[n+1] = (0.4 * y[n] + 
                  0.4 * y[n] * y[n-delay] + 
                  0.6 * (u[n]**3) + 
                  0.1)
    
    # Return input-output pairs
    inputs = u[delay:-1]  # Input sequence u(n)
    targets = y[delay+1:]  # Target sequence y(n+1)
    
    print(f"Generated {len(inputs)} input-output pairs")
    print(f"Input range: [{np.min(inputs):.3f}, {np.max(inputs):.3f}]")
    print(f"Target range: [{np.min(targets):.3f}, {np.max(targets):.3f}]")
    
    return inputs, targets

def generate_narma10_dataset(n_samples: int = 2000) -> Tuple[np.ndarray, np.ndarray]:
    """
    Generate NARMA10 benchmark dataset (more challenging)
    
    y(n+1) = 0.3 * y(n) + 0.05 * y(n) * sum(y(n-i) for i in range(10)) + 1.5 * u(n-9) * u(n) + 0.1
    """
    print(f"Generating NARMA10 dataset with {n_samples} samples")
    
    np.random.seed(42)
    u = np.random.uniform(0, 0.5, n_samples + 10)
    y = np.zeros(n_samples + 10)
    
    # Initial conditions
    y[:10] = np.random.uniform(0, 0.1, 10)
    
    for n in range(9, n_samples + 9):
        y_sum = np.sum(y[n-9:n+1])  # sum of y(n-i) for i in range(10)
        y[n+1] = (0.3 * y[n] + 
                  0.05 * y[n] * y_sum + 
                  1.5 * u[n-9] * u[n] + 
                  0.1)
    
    inputs = u[9:-1]
    targets = y[10:]
    
    print(f"Generated {len(inputs)} input-output pairs")
    print(f"Input range: [{np.min(inputs):.3f}, {np.max(inputs):.3f}]")
    print(f"Target range: [{np.min(targets):.3f}, {np.max(targets):.3f}]")
    
    return inputs, targets

def evaluate_narma_performance(y_true: np.ndarray, y_pred: np.ndarray) -> dict:
    """
    Evaluate performance on NARMA task with standard metrics
    """
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    
    # Normalized Root Mean Square Error (NRMSE)
    rmse = np.sqrt(mse)
    nrmse = rmse / np.std(y_true)
    
    # Correlation coefficient
    correlation = np.corrcoef(y_true, y_pred)[0, 1]
    
    return {
        'mse': mse,
        'mae': mae,
        'rmse': rmse,
        'nrmse': nrmse,
        'correlation': correlation
    }

def main():
    """Main execution function"""
    print("=== Quantum Reservoir Computing for NARMA Benchmarks ===\n")
    
    # Test both NARMA2 and NARMA10 tasks
    narma_tasks = [
        ('NARMA2', lambda: generate_narma2_dataset(2000, delay=2)),
        ('NARMA10', lambda: generate_narma10_dataset(2000))
    ]
    
    all_results = {}
    
    for task_name, data_generator in narma_tasks:
        print(f"\n{'='*50}")
        print(f"Testing on {task_name} Benchmark")
        print(f"{'='*50}")
        
        # Generate dataset
        X_data, y_data = data_generator()
        
        # Normalize data to [-1, 1] range for better quantum processing
        X_scaler = MinMaxScaler(feature_range=(-1, 1))
        y_scaler = MinMaxScaler(feature_range=(-1, 1))
        
        X_normalized = X_scaler.fit_transform(X_data.reshape(-1, 1)).flatten()
        y_normalized = y_scaler.fit_transform(y_data.reshape(-1, 1)).flatten()
        
        # Split data (80% train, 20% test)
        split_idx = int(0.8 * len(X_normalized))
        X_train, X_test = X_normalized[:split_idx], X_normalized[split_idx:]
        y_train, y_test = y_normalized[:split_idx], y_normalized[split_idx:]
        
        print(f"Training samples: {len(X_train)}")
        print(f"Test samples: {len(X_test)}")
        
        # Test different noise configurations
        noise_configs = [
            {
                'name': 'No Noise',
                'factors': {
                    'amplitude_damping': 0.0,
                    'phase_damping': 0.0,
                    'depolarizing': 0.0,
                    'thermal': 0.0,
                    'shot_noise': 0.0,
                    'control_noise': 0.0
                }
            },
            {
                'name': 'Low Noise',
                'factors': {
                    'amplitude_damping': 0.001,
                    'phase_damping': 0.002, 
                    'depolarizing': 0.0005,
                    'thermal': 0.0001,
                    'shot_noise': 0.01,
                    'control_noise': 0.002
                }
            },
            {
                'name': 'Optimal Noise',
                'factors': {
                    'amplitude_damping': 0.005,
                    'phase_damping': 0.01,
                    'depolarizing': 0.002,
                    'thermal': 0.0005,
                    'shot_noise': 0.05,
                    'control_noise': 0.01
                }
            },
            {
                'name': 'High Noise',
                'factors': {
                    'amplitude_damping': 0.02,
                    'phase_damping': 0.05,
                    'depolarizing': 0.01,
                    'thermal': 0.002,
                    'shot_noise': 0.15,
                    'control_noise': 0.03
                }
            }
        ]
        
        task_results = []
        
        # Test each noise configuration
        for config in noise_configs:
            print(f"\n--- Testing {config['name']} Configuration ---")
            
            # Create quantum reservoir with task-specific parameters
            if task_name == 'NARMA2':
                qrc = QuantumReservoirComputing(
                    n_qubits=5,
                    reservoir_size=40,
                    spectral_radius=0.9,
                    input_scaling=0.3,
                    noise_factors=config['factors']
                )
            else:  # NARMA10
                qrc = QuantumReservoirComputing(
                    n_qubits=6,
                    reservoir_size=60,
                    spectral_radius=0.95,
                    input_scaling=0.4,
                    noise_factors=config['factors']
                )
            
            try:
                # Train
                qrc.train(X_train, y_train, reg_param=1e-5)
                
                # Predict
                y_pred_norm = qrc.predict(X_test)
                
                # Denormalize predictions for evaluation
                y_pred = y_scaler.inverse_transform(y_pred_norm.reshape(-1, 1)).flatten()
                y_test_denorm = y_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
                
                # Evaluate
                metrics = evaluate_narma_performance(y_test_denorm, y_pred)
                
                print(f"MSE: {metrics['mse']:.6f}")
                print(f"MAE: {metrics['mae']:.6f}")
                print(f"NRMSE: {metrics['nrmse']:.6f}")
                print(f"Correlation: {metrics['correlation']:.6f}")
                
                task_results.append({
                    'config': config['name'],
                    'metrics': metrics,
                    'predictions': y_pred_norm,
                    'y_test': y_test
                })
                
            except Exception as e:
                print(f"Error with {config['name']}: {e}")
                continue
        
        all_results[task_name] = task_results
        
        # Plot results for this task
        if task_results:
            plot_narma_results(task_name, X_data, y_data, task_results, split_idx)
    
    # Print comprehensive summary
    print_summary(all_results)

def plot_narma_results(task_name: str, X_data: np.ndarray, y_data: np.ndarray, 
                      results: List[dict], split_idx: int):
    """Plot results for NARMA task"""
    plt.figure(figsize=(16, 12))
    
    # Plot 1: Original NARMA time series
    plt.subplot(3, 2, 1)
    plt.plot(X_data[:500], 'b-', alpha=0.7, label='Input u(n)')
    plt.plot(y_data[:500], 'r-', alpha=0.7, label='Target y(n+1)')
    plt.title(f'{task_name} Time Series (First 500 points)')
    plt.xlabel('Time')
    plt.ylabel('Value')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Plot 2: Input-output relationship
    plt.subplot(3, 2, 2)
    plt.scatter(X_data[::10], y_data[::10], alpha=0.5, s=1)
    plt.title(f'{task_name} Input-Output Relationship')
    plt.xlabel('Input u(n)')
    plt.ylabel('Target y(n+1)')
    plt.grid(True, alpha=0.3)
    
    # Plot 3: Predictions comparison
    plt.subplot(3, 2, 3)
    test_range = slice(0, min(100, len(results[0]['y_test'])))
    plt.plot(results[0]['y_test'][test_range], 'k-', label='True', linewidth=2)
    
    colors = ['blue', 'green', 'orange', 'red']
    for i, result in enumerate(results):
        if i < len(colors):
            nrmse = result['metrics']['nrmse']
            plt.plot(result['predictions'][test_range], '--', 
                    color=colors[i], alpha=0.8,
                    label=f"{result['config']} (NRMSE: {nrmse:.3f})")
    
    plt.title(f'{task_name} Predictions (First 100 test points)')
    plt.xlabel('Time')
    plt.ylabel('Normalized Value')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Plot 4: NRMSE comparison
    plt.subplot(3, 2, 4)
    configs = [r['config'] for r in results]
    nrmses = [r['metrics']['nrmse'] for r in results]
    bars = plt.bar(configs, nrmses, alpha=0.7, color=['blue', 'green', 'orange', 'red'][:len(results)])
    plt.title(f'{task_name} NRMSE by Noise Configuration')
    plt.ylabel('NRMSE')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar, nrmse in zip(bars, nrmses):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{nrmse:.3f}', ha='center', va='bottom')
    
    # Plot 5: Correlation comparison
    plt.subplot(3, 2, 5)
    correlations = [r['metrics']['correlation'] for r in results]
    bars = plt.bar(configs, correlations, alpha=0.7, color=['blue', 'green', 'orange', 'red'][:len(results)])
    plt.title(f'{task_name} Correlation by Noise Configuration')
    plt.ylabel('Correlation')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)
    
    # Add value labels on bars
    for bar, corr in zip(bars, correlations):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{corr:.3f}', ha='center', va='bottom')
    
    # Plot 6: Scatter plot of predictions vs true values
    plt.subplot(3, 2, 6)
    best_result = min(results, key=lambda x: x['metrics']['nrmse'])
    y_true = best_result['y_test'][:200]
    y_pred = best_result['predictions'][:200]
    
    plt.scatter(y_true, y_pred, alpha=0.6, s=10)
    min_val, max_val = min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)
    plt.title(f'{task_name} Best Predictions vs True Values')
    plt.xlabel('True Values')
    plt.ylabel('Predicted Values')
    plt.grid(True, alpha=0.3)
    
    plt.suptitle(f'{task_name} Quantum Reservoir Computing Results', fontsize=16)
    plt.tight_layout()
    plt.show()

def print_summary(all_results: dict):
    """Print comprehensive summary of all results"""
    print("\n" + "="*70)
    print("COMPREHENSIVE RESULTS SUMMARY")
    print("="*70)
    
    for task_name, results in all_results.items():
        if not results:
            continue
            
        print(f"\n{task_name} Results:")
        print("-" * 40)
        
        # Find best configuration
        best_result = min(results, key=lambda x: x['metrics']['nrmse'])
        
        print(f"Best Configuration: {best_result['config']}")
        print(f"Best NRMSE: {best_result['metrics']['nrmse']:.6f}")
        print(f"Best Correlation: {best_result['metrics']['correlation']:.6f}")
        
        print(f"\nAll Configurations:")
        for result in results:
            metrics = result['metrics']
            print(f"  {result['config']:15s}: NRMSE={metrics['nrmse']:.6f}, "
                  f"Corr={metrics['correlation']:.6f}")
    
    print(f"\n{'='*70}")
    print("NOISE ANALYSIS:")
    print("="*70)
    print("â€¢ Quantum noise acts as natural regularization")
    print("â€¢ Optimal noise levels prevent overfitting while maintaining dynamics")
    print("â€¢ Different NARMA tasks may benefit from different noise configurations")
    print("â€¢ Noise enhances quantum state exploration and reservoir dynamics")
    print("â€¢ Too much noise degrades performance, too little reduces robustness")

if __name__ == "__main__":
    main()